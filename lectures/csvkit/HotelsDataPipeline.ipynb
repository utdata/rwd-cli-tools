{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotels data pipeline\n",
    "====================\n",
    "\n",
    "We'll use this notebook to show how to build a data pipeline to process data. This could also be rerun with new data if need be.* \n",
    "\n",
    "We'll be using Hotel Occupancy Tax Receipts data, which can be used to see which hotels around the state pull in the most money. For more information about the data itself, see this [README.md](https://github.com/utdata/cli-tools/blob/master/data/hoteltax/README.md).\n",
    "\n",
    "## The Goal\n",
    "\n",
    "* We're going to download one year of quarterly report files.\n",
    "* We'll add a header file\n",
    "* We'll then pull out just hotels in Austin.\n",
    "* We'll convert them into normalized, well-formatted csv files.\n",
    "* We'll then put all the Austin files into a single big file.\n",
    "\n",
    "(One note on this ... I would usually normalize all the data and not just the Austin records, but it takes a little while to run on big files, so we'll cut it down first.)\n",
    "\n",
    "## Windows\n",
    "\n",
    "I'm having trouble getting the bash_kernel to work on Windows. You can use `Git Bash` to run all these commands seperately, without being in a notebook. It's not ideal because you can't annotate them or rerun them unless we put them in a Bash script. You might want to use a lab computer instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "This resets this project to a beginning point. Not certain I'll keep it for realz.\n",
    "\n",
    "A couple of very important things:\n",
    "\n",
    "* The `cd` path needs to go to our class code directory, which I suggest you create in your Documents folder, calling it **rwd**.\n",
    "* the project name, `hotels` in this case, needs to set to something that doesn't already exist for something else. In other works, if you use this to start your own project, make sure you set a new project name so you don't delete this hotels work.\n",
    "* Start `jupyter notebook` from your class folder and save your .ipynb files there. Do NOT save your ipynb file inside your project folder or you will delete it with the following commands!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/hotels\r\n"
     ]
    }
   ],
   "source": [
    "# cd to working directory\n",
    "cd ~/Documents/rwd/\n",
    "# remove existing hotels directory if there\n",
    "mkdir -p hotels\n",
    "# remove contents of hotels\n",
    "rm -rf hotels/*\n",
    "# move into it\n",
    "cd hotels\n",
    "# make sure you are there\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Getting the data\n",
    "\n",
    "We'll use a new command called `curl` to download our data. For more information on curl, you can read the [man page](https://curl.haxx.se/docs/manpage.html) or this [handy tip sheet](http://www.thegeekstuff.com/2012/04/curl-examples/), which is much more understandable.\n",
    "\n",
    "Since we are in a Bash notebook, we can use our command-line tools. Let's make sure we know where we are. Type in `pwd` in the prompt below and then do shift-return to execute the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/hotels\r\n"
     ]
    }
   ],
   "source": [
    "# make sure we are starting in the `hotels` directory\n",
    "# if you aren't, then get there.\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the raw data\n",
    "Ok, we need will create a new folder called `data`, where we will store our raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/hotels/data\r\n"
     ]
    }
   ],
   "source": [
    "# create the directory\n",
    "mkdir data\n",
    "# move into the directory\n",
    "cd data\n",
    "# show we are inside `hotels/data`\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data\n",
    "If you read about the tax data in the intro, you'll see you can get it from the comptroller, but they have some naming issues, so to help with this assignment, I've saved the data and we'll pull it down from this [github repo](https://github.com/utdata/cli-tools/tree/master/hoteltax/data). Open that link in a new window and look at it.\n",
    "\n",
    "* `header.csv` is a file I created that has the header names. It will get used later.\n",
    "* The next 10 files that end with `hotl15XX.csv` are monthly files for 2015.\n",
    "* The last four that end with `hotl15qX.csv` are the quarterly files are are after in for this example.\n",
    "\n",
    "### curl\n",
    "Now we'll use `curl` to pull down a quarterly hotel tax file. Let's do it first as it takes a couple seconds to run, then I'll explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  9 4674k    9  463k    0     0   234k      0  0:00:19  0:00:01  0:00:18  319k\r",
      " 36 4674k   36 1693k    0     0   571k      0  0:00:08  0:00:02  0:00:06  694k\r",
      " 73 4674k   73 3454k    0     0   870k      0  0:00:05  0:00:03  0:00:02 1003k\r",
      " 99 4674k   99 4657k    0     0   937k      0  0:00:04  0:00:04 --:--:-- 1048k\r",
      "100 4674k  100 4674k    0     0   941k      0  0:00:04  0:00:04 --:--:-- 1365k\r\n"
     ]
    }
   ],
   "source": [
    "curl -O -L https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down that `curl` statement.\n",
    "\n",
    "* `curl` is the command. I think of it as \"capture URL\". [man curl](http://man.cx/curl)\n",
    "* `-O` (that's capital O, not zero). This outputs result to a file to your computer instead of to your screen, using the same file name as it was originally.\n",
    "* `-L` stands for `--location`, and it will allow the request to follow a redirect link. It's good to use it.\n",
    "* And then we have the url of the file.\n",
    "\n",
    "Let's check that the file made it to our computer, and if some data in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9352\r\n",
      "-rw-r--r--  1 christian  staff  4786600 Jul 17 13:52 hotl15q1.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is there, and it is 4.7M. Pretty big file.\n",
    "\n",
    "Because our file names are well formatted, we can pull down multiple files at the same time. The quarterly file names have `hotl` followed by `q` for quarter, then a number for that quarter. There is a feature in `curl` where we can get sequences of alphanumeric series in the url by using [].\n",
    "\n",
    "* `file[1-4].csv` would get you file1.csv, file2.csv, file3.csv and file4.csv.\n",
    "* If numbers are 0-based, like file01.csv, then you can do it like this: `file[01-04].csv`.\n",
    "\n",
    "Our are don't have the zero spacing, but the monthly files do. Remember that for your assignment ;-).\n",
    "\n",
    "Let's pull down the four quarterly files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[1/4]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q1.csv --> hotl15q1.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q1.csv\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 12 4674k   12  591k    0     0   339k      0  0:00:13  0:00:01  0:00:12  501k\r",
      " 33 4674k   33 1583k    0     0   614k      0  0:00:07  0:00:02  0:00:05  784k\r",
      " 54 4674k   54 2559k    0     0   716k      0  0:00:06  0:00:03  0:00:03  850k\r",
      " 70 4674k   70 3295k    0     0   717k      0  0:00:06  0:00:04  0:00:02  817k\r",
      " 86 4674k   86 4031k    0     0   723k      0  0:00:06  0:00:05  0:00:01  824k\r",
      "100 4674k  100 4674k    0     0   719k      0  0:00:06  0:00:06 --:--:--  857k\r\n",
      "\r\n",
      "[2/4]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q2.csv --> hotl15q2.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q2.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  1 4768k    1 97512    0     0  90014      0  0:00:54  0:00:01  0:00:53  271k\r",
      " 11 4768k   11  527k    0     0   253k      0  0:00:18  0:00:02  0:00:16  391k\r",
      " 35 4768k   35 1679k    0     0   548k      0  0:00:08  0:00:03  0:00:05  720k\r",
      " 54 4768k   54 2591k    0     0   637k      0  0:00:07  0:00:04  0:00:03  777k\r",
      " 82 4768k   82 3919k    0     0   773k      0  0:00:06  0:00:05  0:00:01  904k\r",
      "100 4768k  100 4768k    0     0   787k      0  0:00:06  0:00:06 --:--:--  940k\r\n",
      "\r\n",
      "[3/4]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q3.csv --> hotl15q3.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q3.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 14 4798k   14  703k    0     0   703k      0  0:00:06 --:--:--  0:00:06  703k\r",
      " 35 4798k   35 1727k    0     0   859k      0  0:00:05  0:00:02  0:00:03  859k\r",
      " 59 4798k   59 2863k    0     0   951k      0  0:00:05  0:00:03  0:00:02  951k\r",
      " 83 4798k   83 3999k    0     0   999k      0  0:00:04  0:00:04 --:--:--  999k\r",
      "100 4798k  100 4798k    0     0  1041k      0  0:00:04  0:00:04 --:--:-- 1041k\r\n",
      "\r\n",
      "[4/4]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q4.csv --> hotl15q4.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q4.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 16 4943k   16  799k    0     0   583k      0  0:00:08  0:00:01  0:00:07  912k\r",
      " 34 4943k   34 1711k    0     0   717k      0  0:00:06  0:00:02  0:00:04  904k\r",
      " 51 4943k   51 2559k    0     0   754k      0  0:00:06  0:00:03  0:00:03  883k\r",
      " 67 4943k   67 3343k    0     0   764k      0  0:00:06  0:00:04  0:00:02  862k\r",
      " 80 4943k   80 3999k    0     0   739k      0  0:00:06  0:00:05  0:00:01  813k\r",
      "100 4943k  100 4943k    0     0   805k      0  0:00:06  0:00:06 --:--:--  869k\r\n"
     ]
    }
   ],
   "source": [
    "curl -O -L https://raw.githubusercontent.com/utdata/cli-tools/master/data/hoteltax/data/hotl15q[1-4].csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will pull down all 4 quarterly files. It takes a little bit, and Jupyter Notebooks will have an asterisk for that line until it is complete. Once it is, we take a look to make sure we have all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 38384\r\n",
      "-rw-r--r--  1 christian  staff  4786600 Jul 17 14:10 hotl15q1.csv\r\n",
      "-rw-r--r--  1 christian  staff  4883450 Jul 17 14:10 hotl15q2.csv\r\n",
      "-rw-r--r--  1 christian  staff  4913675 Jul 17 14:10 hotl15q3.csv\r\n",
      "-rw-r--r--  1 christian  staff  5062200 Jul 17 14:10 hotl15q4.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a header row\n",
    "\n",
    "Let's take a look at the top of the first file. We'll use a command called `head` which looks at the first ten lines of the file. We'll also show that tab complete works here, so type in head hot and then hit tab, and you'll get a pop-up that shows available files to choose from. Choose the right one, then use shift-return to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,     10122.08,      6372.08\r",
      "\r\n",
      "32054882710,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",000,00001,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",   ,    3,      4924.00,      4924.00\r",
      "\r\n",
      "32038336601,\"HAGEMAN RESERVE LLC                               \",\"147 DUNHAM RANCH RD                     \",\"SULPHUR BLUFF       \",\"TX\",\"75481\",112,00003,\"HAGEMAN RESERVE LLC                               \",\"8910 PURDUE RD                          \",\"INDIANAPOLIS        \",\"IN\",\"46268\",   ,   29,     51800.79,     51800.79\r",
      "\r\n",
      "32051814922,\"BRETT BAER                                        \",\"5455 WILSHIRE BLVD STE 914              \",\"LOS ANGELES         \",\"CA\",\"90036\",000,00001,\"BRETT BAER                                        \",\"5455 WILSHIRE BLVD STE 914              \",\"LOS ANGELES         \",\"CA\",\"90036\",   ,    6,     56456.03,     56456.03\r",
      "\r\n",
      "32040003603,\"PINE DUNES LODGE, LLC                             \",\"5951 PRESTON GATE CT                    \",\"DALLAS              \",\"TX\",\"75230\",057,00001,\"PINE DUNES LODGE, LLC                             \",\"159 PRIVATE ROAD 7019                   \",\"FRANKSTON           \",\"TX\",\"75763\",001,   11,     15408.41,     15408.41\r",
      "\r\n",
      "19201919875,\"SKYTRAQS, LLC                                     \",\"PO BOX 534                              \",\"FRANKSTON           \",\"TX\",\"75763\",001,00001,\"SKYTRAQS LLC                                      \",\"10593 COUNTY ROAD 4101                  \",\"FRANKSTON           \",\"TX\",\"75763\",001,    5,      5590.26,      5590.26\r",
      "\r\n",
      "32025037428,\"PETER E FAY                                       \",\"PO BOX 153                              \",\"CHAPPELL HILL       \",\"TX\",\"77426\",001,00001,\"'R' PLACE RV PARK AND CAMPGROUND                  \",\"14000 E US HIGHWAY 84                   \",\"PALESTINE           \",\"TX\",\"75801\",001,    1,         0.00,         0.00\r",
      "\r\n",
      "12519244599,\"PRAYOGI, LLC                                      \",\"1601 W PALESTINE AVE                    \",\"PALESTINE           \",\"TX\",\"75801\",001,00001,\"BEST WESTERN PALESTINE INN                        \",\"1601 W PALESTINE AVE                    \",\"PALESTINE           \",\"TX\",\"75801\",001,   66,    234194.05,    213790.34\r",
      "\r\n",
      "32053097765,\"EDGAR MERCADO                                     \",\"2033 HAWKEN DR                          \",\"PLANO               \",\"TX\",\"75023\",043,00001,\"DAYS INN                                          \",\"1101 E PALESTINE AVE                    \",\"PALESTINE           \",\"TX\",\"75801\",001,   84,         0.00,         0.00\r",
      "\r\n",
      "32036715889,\"JAMES F COLVIN                                    \",\"18141 FM 315                            \",\"PALESTINE           \",\"TX\",\"75803\",001,00001,\"DEER CREEK MEADOWS                                \",\"18141 FM 315                            \",\"PALESTINE           \",\"TX\",\"75803\",001,    3,         0.00,         0.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "head hotl15q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this looks like something, but we don't have a header row, which sucks. We can compare it against our [table layout](https://github.com/utdata/cli-tools/blob/master/hoteltax/HOTELTAX_LYOT.TXT), copied here:\n",
    "\n",
    "```\n",
    "Column_Order|Column_Description|Data_Type|Size\n",
    "Col01|Taxpayer Number|Number|11\n",
    "Col02|Taxpayer Name|Char|50\n",
    "Col03|Taxpayer Address|Char|40\n",
    "Col04|Taxpayer City|Char|20\n",
    "Col05|Taxpayer State|Char|2\n",
    "Col06|Taxpayer Zip Code|Number|5\n",
    "Col07|Taxpayer County|Number|3\n",
    "Col08|Outlet Number|Number|5\n",
    "Col09|Location Name|Char|50\n",
    "Col10|Location Address|Char|40\n",
    "Col11|Location City|Char|20\n",
    "Col12|Location State|Char|2\n",
    "Col13|Location Zip Code|Number|5\n",
    "Col14|Location County|Number|3\n",
    "Col15|Location Room Capacity|Number|5\n",
    "Col16|Location Tot Room Receipts|Number|13\n",
    "Col17|Location Taxable Receipts|Number|13\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### editing a file in place\n",
    "\n",
    "We need to add a header row to all of these files or we'll have problems later. This is one place that we are making changes to the original file, though we'll make a backup while we're doing it, and then remove them. We could do this manually, but even with a text editor, it can be tricky because the file are so big.\n",
    "\n",
    "We'll use a command-line program called `sed`. I'll be honest, this took me a couple of hours to figure out, especially since Mac handles `sed -i` differently than unix, and I thought I was going crazy. So, this is possibly a Mac-only solution.\n",
    "\n",
    "First, we need the text that will go in the header row. I built this by hand based on the layout file above:\n",
    "\n",
    "```\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "```\n",
    "\n",
    "Here is the command to change one of the files, and then I'll explain it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# adding header row to q1\n",
    "# if on Windows, leave out the '.bak' part\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl15q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's take a look at that file to make sure the header line was added properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,     10122.08,      6372.08\r",
      "\r\n",
      "32054882710,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",000,00001,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",   ,    3,      4924.00,      4924.00\r",
      "\r\n",
      "32038336601,\"HAGEMAN RESERVE LLC                               \",\"147 DUNHAM RANCH RD                     \",\"SULPHUR BLUFF       \",\"TX\",\"75481\",112,00003,\"HAGEMAN RESERVE LLC                               \",\"8910 PURDUE RD                          \",\"INDIANAPOLIS        \",\"IN\",\"46268\",   ,   29,     51800.79,     51800.79\r",
      "\r\n",
      "32051814922,\"BRETT BAER                                        \",\"5455 WILSHIRE BLVD STE 914              \",\"LOS ANGELES         \",\"CA\",\"90036\",000,00001,\"BRETT BAER                                        \",\"5455 WILSHIRE BLVD STE 914              \",\"LOS ANGELES         \",\"CA\",\"90036\",   ,    6,     56456.03,     56456.03\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# checking header q1\n",
    "head -n 5 hotl15q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks good. Now, let's do this for the other 3 files. (We don't want to do the first one again, or we'll add the header twice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# adding headers for q2-q4\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl15q2.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl15q3.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl15q4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first two lines of all the files to make sure it is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,     10122.08,      6372.08\r",
      "\r\n",
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,      6374.98,      6374.98\r",
      "\r\n",
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,     12158.27,     12158.27\r",
      "\r\n",
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32054882710,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",000,00001,\"HOLIDAY HACIENDAS LLC                             \",\"25500 BRUSH COLLEGE RD                  \",\"HARRISONVILLE       \",\"MO\",\"64701\",   ,    3,      2350.00,      2350.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# checking for header rows\n",
    "head -n 2 hotl15q1.csv\n",
    "head -n 2 hotl15q2.csv\n",
    "head -n 2 hotl15q3.csv\n",
    "head -n 2 hotl15q4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing bak files\n",
    "Now, one thing about this ... The `sed` command created a bunch of *.bak* files as backups that we'll need to get rid of. To do so, we get to use the power of `rm`.\n",
    "\n",
    "(If you ran the `sed` command on windows without the `'.bak'` part, you won't have the backup files.)\n",
    "\n",
    "Let's look at the directory first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 76768\r\n",
      "-rw-r--r--  1 christian  staff  4786894 Jul 17 14:10 hotl15q1.csv\r\n",
      "-rw-r--r--  1 christian  staff  4786600 Jul 17 14:10 hotl15q1.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  4883744 Jul 17 14:10 hotl15q2.csv\r\n",
      "-rw-r--r--  1 christian  staff  4883450 Jul 17 14:10 hotl15q2.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  4913969 Jul 17 14:10 hotl15q3.csv\r\n",
      "-rw-r--r--  1 christian  staff  4913675 Jul 17 14:10 hotl15q3.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  5062494 Jul 17 14:10 hotl15q4.csv\r\n",
      "-rw-r--r--  1 christian  staff  5062200 Jul 17 14:10 hotl15q4.csv.bak\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove all the files with .bak in the name, and then `ls` the directory again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 38384\r\n",
      "-rw-r--r--  1 christian  staff  4786894 Jul 17 14:10 hotl15q1.csv\r\n",
      "-rw-r--r--  1 christian  staff  4883744 Jul 17 14:10 hotl15q2.csv\r\n",
      "-rw-r--r--  1 christian  staff  4913969 Jul 17 14:10 hotl15q3.csv\r\n",
      "-rw-r--r--  1 christian  staff  5062494 Jul 17 14:10 hotl15q4.csv\r\n"
     ]
    }
   ],
   "source": [
    "# removes files that end with .bak\n",
    "rm *.bak\n",
    "# lists the directory again to check\n",
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grep for Austin, normalize the files\n",
    "\n",
    "A couple of things about that file. Note that Col02, Taxpayer name is 50 characters long. Look at the first line of data:\n",
    "\n",
    "```\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "32015066601,\"JENNIFER SALES                                    \",\"6363 S NETHERLAND WAY                   \",\"CENTENNIAL          \",\"CO\",\"80016\",000,00001,\"PEAK2PAR                                          \",\"22018 E COSTILLA DR                     \",\"AURORA              \",\"CO\",\"80016\",   ,    1,     10122.08,      6372.08\n",
    "```\n",
    "\n",
    "Notice anything about that \"JENNIFER SALES\" name? That name is in quotes, but look where quote mark closes. That field uses the full 50 characters, filled in with spaces. Same for the address, and all the other fields. This is one of the things **csvkit** can help us with, cleaning up and normalizing a csv file.( You might want to have the [csvkit docs](https://csvkit.readthedocs.io) open as a reference as we go through this.)\n",
    "\n",
    "We want to use this technique on our files, but they are pretty big and it would take some time. So, to save some time and to show you the power of **pipes**, we'll find just our Austin hotels and then normalize that data.\n",
    "\n",
    "Let's move out of our data directory and create a new one to put our processed data into, so it is separated from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/hotels\r\n"
     ]
    }
   ],
   "source": [
    "# moving out of data into hotels\n",
    "cd ../\n",
    "# making sure we are in hotels\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  6 christian  staff  204 Jul 17 14:11 data\r\n",
      "drwxr-xr-x  2 christian  staff   68 Jul 17 14:11 data-done\r\n"
     ]
    }
   ],
   "source": [
    "# make our data-done directory\n",
    "# we use the -p here so it won't error if it already exists\n",
    "mkdir -p data-done\n",
    "# list just to show it was created\n",
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csvcut to see columns\n",
    "\n",
    "Let's use [csvcut](https://csvkit.readthedocs.io/en/540/scripts/csvcut.html) with the `-n` option to peak at the header row of the first file to confirm our Location City column. The `-n` stands for `--names`, because it is usually used to see the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Taxpayer Number\r\n",
      "  2: Taxpayer Name\r\n",
      "  3: Taxpayer Address\r\n",
      "  4: Taxpayer City\r\n",
      "  5: Taxpayer State\r\n",
      "  6: Taxpayer Zip Code\r\n",
      "  7: Taxpayer County\r\n",
      "  8: Outlet Number\r\n",
      "  9: Location Name\r\n",
      " 10: Location Address\r\n",
      " 11: Location City\r\n",
      " 12: Location State\r\n",
      " 13: Location Zip Code\r\n",
      " 14: Location County\r\n",
      " 15: Location Room Capacity\r\n",
      " 16: Location Tot Room Receipts\r\n",
      " 17: Location Taxable Receipts\r\n"
     ]
    }
   ],
   "source": [
    "csvcut -n data/hotl15q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grep for Austin\n",
    "\n",
    "OK, we can see `Location City` is in the 11th column, which looks good. We can use `csvgrep` to find the AUSTIN rows.\n",
    "\n",
    "Grep is a command-line tool for regular expressions, and [csvgrep](https://csvkit.readthedocs.io/en/540/scripts/csvgrep.html) works the same way. It needs a couple of arguments:\n",
    "\n",
    "* `-c` is which column to search. We want `11`.\n",
    "* `-m` you would use to match an exact string. We could instead use `-r` to build a regular expression.\n",
    "\n",
    "We know we need column 11, but the match word will be tricky. We can't search for just the word \"AUSTIN\" because the \n",
    "\n",
    "The other thing we are going to do is to **pipe** the result into another command, `head` in this case. This is so we can just look at the first couple of lines to test our output before using it. This **pipe** concept is really important: You can take the \"out\" result of command and make it the \"in\" command of another, and you can string these together into a pipeline. That's what we're working on here, piece by piece ... a pipeline to cut and clean our files.\n",
    "\n",
    "So, our `csvgrep` command searches the 11th column for the word AUSTIN at the beginning (the ^). We then pipe it into `head` and use the `-n` flag to show just 5 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32051871906,DSN HOSPITALITY LLC                               ,4710 S LAMAR BLVD                       ,AUSTIN              ,TX,78745,227,00001,DSN HOSPITALITY LLC                               ,3110 STATE HIGHWAY 71 EAST              ,AUSTIN              ,TX,78745,011,   37,     91205.03,     90870.01\r\n",
      "32054409241,JEANETTE WELSHE                                   ,13801 EVERGREEN WAY                     ,AUSTIN              ,TX,78737,105,00001,BED AND BREAKFAST                                 ,13801 EVERGREEN WAY                     ,AUSTIN              ,TX,78737,105,    4,      5417.92,      5417.92\r\n",
      "32047098168,AMY MARIE CAPUTO                                  ,13601 PAISANO CIR                       ,AUSTIN              ,TX,78737,105,00001,FLORA PROPERTIES/AMY M. CAPUTO                    ,13601 PAISANO CIR                       ,AUSTIN              ,TX,78737,105,    4,      7280.23,      7280.23\r\n",
      "32055460730,NATHANIEL R BAUERNFEIND                           ,163 KINLOCH CT                          ,AUSTIN              ,TX,78737,105,00001,NATHANIEL R BAUERNFEIND                           ,163 KINLOCH CT                          ,AUSTIN              ,TX,78737,105,    1,      4735.00,      4735.00\r\n"
     ]
    }
   ],
   "source": [
    "# grop for austin, show first 5 lines\n",
    "csvgrep -c 11 -r '^AUSTIN' data/hotl15q1.csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OK, that looks like we are getting the right row. Now we are going to pipe that result into `in2csv` to normalize it and then again into `head` so we just look at the top of the file.\n",
    "\n",
    "In this case, `in2csv` needs a `-f` flag for filetype, which we will set as `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32051871906,DSN HOSPITALITY LLC,4710 S LAMAR BLVD,AUSTIN,TX,78745,227,00001,DSN HOSPITALITY LLC,3110 STATE HIGHWAY 71 EAST,AUSTIN,TX,78745,011,37,91205.03,90870.01\r\n",
      "32054409241,JEANETTE WELSHE,13801 EVERGREEN WAY,AUSTIN,TX,78737,105,00001,BED AND BREAKFAST,13801 EVERGREEN WAY,AUSTIN,TX,78737,105,4,5417.92,5417.92\r\n",
      "32047098168,AMY MARIE CAPUTO,13601 PAISANO CIR,AUSTIN,TX,78737,105,00001,FLORA PROPERTIES/AMY M. CAPUTO,13601 PAISANO CIR,AUSTIN,TX,78737,105,4,7280.23,7280.23\r\n",
      "32055460730,NATHANIEL R BAUERNFEIND,163 KINLOCH CT,AUSTIN,TX,78737,105,00001,NATHANIEL R BAUERNFEIND,163 KINLOCH CT,AUSTIN,TX,78737,105,1,4735.0,4735.0\r\n"
     ]
    }
   ],
   "source": [
    "# grep for austin, convert to csv, show first five lines\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q1.csv | in2csv -f csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference in the files now? All the bad space is gone. We can take that command above and instead of piping it into `head`, we can redirect it into a new file in the data-done folder. We do this with `>` and then specify the file location, which we'll call `hotl15q1-austin.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# grep for austin, convert to csv, put in new file\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q1.csv | in2csv -f csv > data-done/hotl15q1-austin.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the new `data-done` directory to see that the finished file is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 448\r\n",
      "-rw-r--r--  1 christian  staff  226903 Jul 17 14:11 hotl15q1-austin.csv\r\n"
     ]
    }
   ],
   "source": [
    "# check for newly-made file in data-done\n",
    "ls -l data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OK, let's go ahead and process all of the files so we have clean versions of the Austin records.\n",
    "\n",
    "(FYI, There is a better way to do this with a loop of some sort, but I don't know how. Yet.)\n",
    "\n",
    "When I set this up, I just copied that first one over 3 more times, then updated the file names in both places on each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Make sure you get the file names right\n",
    "# this will take a couple of seconds\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q1.csv | in2csv -f csv > data-done/hotl15q1-austin.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q2.csv | in2csv -f csv > data-done/hotl15q2-austin.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q3.csv | in2csv -f csv > data-done/hotl15q3-austin.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl15q4.csv | in2csv -f csv > data-done/hotl15q4-austin.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1800\r\n",
      "-rw-r--r--  1 christian  staff  226903 Jul 17 14:11 hotl15q1-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  224339 Jul 17 14:11 hotl15q2-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  225120 Jul 17 14:11 hotl15q3-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  238415 Jul 17 14:11 hotl15q4-austin.csv\r\n"
     ]
    }
   ],
   "source": [
    "# making sure they are all there\n",
    "ls -l data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack into a single file\n",
    "\n",
    "Now we can use [csvstack](https://csvkit.readthedocs.io/en/540/scripts/csvstack.html) to combine all the files into one big file.\n",
    "\n",
    "* **-g** flag lets us create a new column and give a value to each row that defines which file it came from. In our case, we need to know what month it came from, so we'll list all the months.\n",
    "* **-n** let's us name that group column. We'll call it Month.\n",
    "\n",
    "Then we list all the files we want to put together. When when use **-g**, which have to have the same number of groupings as we do input files.\n",
    "\n",
    "I'm breaking this command up into multiple lines using \"\\\" at the end so you can see the whole command. The group names and the files need to be in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "csvstack -n Quarter -g Q1,Q2,Q3,Q4 \\\n",
    "data-done/hotl15q1-austin.csv data-done/hotl15q2-austin.csv \\\n",
    "data-done/hotl15q3-austin.csv data-done/hotl15q4-austin.csv \\\n",
    "> data-done/austin-hotels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `ls` that directory to make sure the new file is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3624\r\n",
      "-rw-r--r--  1 christian  staff  931618 Jul 17 14:12 austin-hotels.csv\r\n",
      "-rw-r--r--  1 christian  staff  226903 Jul 17 14:11 hotl15q1-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  224339 Jul 17 14:11 hotl15q2-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  225120 Jul 17 14:11 hotl15q3-austin.csv\r\n",
      "-rw-r--r--  1 christian  staff  238415 Jul 17 14:11 hotl15q4-austin.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick stats on files\n",
    "\n",
    "We'll use [csvstat](https://csvkit.readthedocs.io/en/540/scripts/csvstat.html) to take a closer look at the combined file. Sometimes the result is all you need for a story ... the min, max, sum, mean and median of a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Quarter\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: Q4, Q2, Q3, Q1\r\n",
      "  2. Taxpayer Number\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 10204561905\r\n",
      "\tMax: 32059607492\r\n",
      "\tSum: 179205405825924\r\n",
      "\tMean: 30348078886.69331\r\n",
      "\tMedian: 32049933412\r\n",
      "\tStandard Deviation: 5292074890.428423\r\n",
      "\tUnique values: 1221\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t32049933412:\t829\r\n",
      "\t\t32052153940:\t104\r\n",
      "\t\t32022337540:\t96\r\n",
      "\t\t32043490237:\t96\r\n",
      "\t\t12016274339:\t48\r\n",
      "  3. Taxpayer Name\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 1226\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTURNKEY VACATION RENTALS, INC.:\t829\r\n",
      "\t\tEMERSON GUEST PROPERTIES LLC:\t104\r\n",
      "\t\tCHEREEN FISHER:\t96\r\n",
      "\t\tVACATIONCAKE LLC:\t96\r\n",
      "\t\tESA P PORTFOLIO OPERATING LESSEE LLC:\t48\r\n",
      "\tMax length: 50\r\n",
      "  4. Taxpayer Address\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 1176\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t4544 S LAMAR BLVD STE G300:\t465\r\n",
      "\t\t4544 S LAMAR BLVD BLDG 300:\t364\r\n",
      "\t\tPO BOX 3089 C/O HOTSPOT TAX SERVICES:\t123\r\n",
      "\t\t707 JOSEPHINE ST:\t104\r\n",
      "\t\t1709 BLUEBONNET LN:\t96\r\n",
      "\tMax length: 40\r\n",
      "  5. Taxpayer City\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 117\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tAUSTIN:\t4832\r\n",
      "\t\tGREENWOOD VLG:\t170\r\n",
      "\t\tMERRILLVILLE:\t79\r\n",
      "\t\tHOUSTON:\t67\r\n",
      "\t\tW LAKE HILLS:\t58\r\n",
      "\tMax length: 14\r\n",
      "  6. Taxpayer State\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: True\r\n",
      "\tUnique values: 31\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTX:\t5304\r\n",
      "\t\tCO:\t197\r\n",
      "\t\tIN:\t83\r\n",
      "\t\tCA:\t72\r\n",
      "\t\tNC:\t52\r\n",
      "\tMax length: 4\r\n",
      "  7. Taxpayer Zip Code\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: True\r\n",
      "\tUnique values: 207\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t78704:\t1104\r\n",
      "\t\t78745:\t926\r\n",
      "\t\t78702:\t464\r\n",
      "\t\t78701:\t376\r\n",
      "\t\t78703:\t358\r\n",
      "\tMax length: 5\r\n",
      "  8. Taxpayer County\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 26\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t227:\t4874\r\n",
      "\t\t000:\t601\r\n",
      "\t\t057:\t99\r\n",
      "\t\t101:\t67\r\n",
      "\t\t246:\t67\r\n",
      "\tMax length: 3\r\n",
      "  9. Outlet Number\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 279\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t00001:\t3187\r\n",
      "\t\t00002:\t801\r\n",
      "\t\t00003:\t246\r\n",
      "\t\t00004:\t122\r\n",
      "\t\t00005:\t99\r\n",
      "\tMax length: 5\r\n",
      " 10. Location Name\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 1621\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTURNKEY VACATION RENTALS:\t178\r\n",
      "\t\tTOP TRIP RENTALS:\t52\r\n",
      "\t\tCHEREEN FISHER:\t44\r\n",
      "\t\tTURNKEY VACATION RENTALS LLC:\t29\r\n",
      "\t\tRAILYARD CONDOMINIUMS:\t28\r\n",
      "\tMax length: 50\r\n",
      " 11. Location Address\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 1687\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t8212 BARTON CLUB DR:\t13\r\n",
      "\t\t2210 UNIVERSITY CLUB DR:\t12\r\n",
      "\t\t1916 TILLOTSON AVE:\t11\r\n",
      "\t\t1715A BLUEBONNET LN:\t9\r\n",
      "\t\t1403 WESTMOOR DR:\t9\r\n",
      "\tMax length: 32\r\n",
      " 12. Location City\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: AUSTIN\r\n",
      " 13. Location State\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: TX\r\n",
      " 14. Location Zip Code\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 78617\r\n",
      "\tMax: 78799\r\n",
      "\tSum: 464832973\r\n",
      "\tMean: 78718.53903471635\r\n",
      "\tMedian: 78704\r\n",
      "\tStandard Deviation: 20.864374964885755\r\n",
      "\tUnique values: 45\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t78704:\t1579\r\n",
      "\t\t78702:\t801\r\n",
      "\t\t78703:\t512\r\n",
      "\t\t78701:\t489\r\n",
      "\t\t78751:\t196\r\n",
      " 15. Location County\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: 227, 246, 105, 011, 178\r\n",
      " 16. Location Room Capacity\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 1\r\n",
      "\tMax: 37211\r\n",
      "\tSum: 232087\r\n",
      "\tMean: 39.3034716342083\r\n",
      "\tMedian: 2\r\n",
      "\tStandard Deviation: 840.6184546588875\r\n",
      "\tUnique values: 148\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t1:\t2341\r\n",
      "\t\t2:\t907\r\n",
      "\t\t3:\t841\r\n",
      "\t\t4:\t543\r\n",
      "\t\t5:\t220\r\n",
      " 17. Location Tot Room Receipts\r\n",
      "\t<class 'float'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 0.0\r\n",
      "\tMax: 18139550.47\r\n",
      "\tSum: 1048678990.8800001\r\n",
      "\tMean: 177591.70040304828\r\n",
      "\tMedian: 6064.93\r\n",
      "\tStandard Deviation: 848029.4100440782\r\n",
      "\tUnique values: 4445\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t0.0:\t1153\r\n",
      "\t\t7500.0:\t8\r\n",
      "\t\t3000.0:\t7\r\n",
      "\t\t2400.0:\t6\r\n",
      "\t\t5000.0:\t6\r\n",
      " 18. Location Taxable Receipts\r\n",
      "\t<class 'float'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 0.0\r\n",
      "\tMax: 17742557.74\r\n",
      "\tSum: 949006245.3799999\r\n",
      "\tMean: 160712.31928535138\r\n",
      "\tMedian: 5199.58\r\n",
      "\tStandard Deviation: 800043.8586673959\r\n",
      "\tUnique values: 4323\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t0.0:\t1292\r\n",
      "\t\t3000.0:\t7\r\n",
      "\t\t2400.0:\t6\r\n",
      "\t\t2100.0:\t5\r\n",
      "\t\t7500.0:\t5\r\n",
      "\r\n",
      "Row count: 5905\r\n"
     ]
    }
   ],
   "source": [
    "csvstat data-done/austin-hotels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result, and possible next steps\n",
    "\n",
    "You can already see a couple of things here.\n",
    "\n",
    "* The most a single hotel reported in a quarter in 2015 was 18,139,550.47\n",
    "* The mean (or average) reported by all establishments was 177,591.70, but given the median is 6064.93 there are many establishments that did not make that much money.\n",
    "\n",
    "Now your single `austin-hotels` file can be analyzed so you are looking at one year of data all together.\n",
    "\n",
    "By having this all in this notebook, you can run the whole process over again by going to the Kernel menu and choosing **Restart and Run All**.\n",
    "\n",
    "If you find you had a mistake somewhere along the line, you can fix it, then **Restart and Run All**.\n",
    "\n",
    "Imagine if you had done all this by hand in Excel, and then found you made an error early in the process. Or, worse yet, you didn't discover you made an error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Best quarter for a hotel\n",
    "\n",
    "You can use all these commands **csvkit** to make a pretty decent display of your data. We're going to string together a command to show the best quarters for hotels based on our processed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------+--------------------------------+---------------------+-----------------------------|\r\n",
      "|  Quarter | Location Name                  | Location Address    | Location Tot Room Receipts  |\r\n",
      "|----------+--------------------------------+---------------------+-----------------------------|\r\n",
      "|  Q4      | JW MARRIOTT AUSTIN DOWNTOWN    | 110 E 2ND ST        | 18139550.47                 |\r\n",
      "|  Q2      | JW MARRIOTT AUSTIN DOWNTOWN    | 110 E 2ND ST        | 17954220.22                 |\r\n",
      "|  Q3      | JW MARRIOTT AUSTIN DOWNTOWN    | 110 E 2ND ST        | 16639896.29                 |\r\n",
      "|  Q1      | AUSTIN HILTON CONVENTION HOTEL | 500 E 4TH ST        | 15510707.02                 |\r\n",
      "|  Q2      | AUSTIN HILTON CONVENTION HOTEL | 500 E 4TH ST        | 14011634.18                 |\r\n",
      "|  Q4      | AUSTIN HILTON CONVENTION HOTEL | 500 E 4TH ST        | 12743324.32                 |\r\n",
      "|  Q1      | JW MARRIOTT AUSTIN DOWNTOWN    | 110 E 2ND ST        | 11833556.27                 |\r\n",
      "|  Q3      | AUSTIN HILTON CONVENTION HOTEL | 500 E 4TH ST        | 11708036.5                  |\r\n",
      "|  Q1      | FOUR SEASONS HOTEL AUSTIN      | 98 SAN JACINTO BLVD | 8421681.51                  |\r\n",
      "|----------+--------------------------------+---------------------+-----------------------------|\r\n"
     ]
    }
   ],
   "source": [
    "# just making sure I'm in the hotels folder\n",
    "cd ~/Documents/rwd/hotels/\n",
    "# get columns, sort by room receipts, get the top, csvlook for display\n",
    "csvcut -c 1,10,11,17 data-done/austin-hotels.csv | csvsort -c 4 -r | head -n 10 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down that command:\n",
    "\n",
    "* `csvcut -c 1,10,11,17 austin-hotels.csv`. I'm using csvcut to just get certain collumns. Remember you can figure out which columns numbers by doing `csvcut -n filename` to get a printout of the first line, usually the header.\n",
    "* `csvsort -c 4 -r` I'm using [csvsort]() here, and I'm sorting on Location Tot Room Receipts, which is now the 4th column since we cut it. I set the `-r` to get descending order to get the most on the top.\n",
    "* `head -n 10` to get just the top 10 from the result of the sort.\n",
    "* `csvlook` makes the nice little table view.\n",
    "\n",
    "The order of this is important. You can't start with `head` or you'll only have the first 10 rows of the file to consider for your sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
