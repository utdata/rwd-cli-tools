{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APD Demographics data pipeline\n",
    "\n",
    "This story started with the receipt of a dozen Excel files, in which each file had eight worksheets. I needed to combine all the data from all the worksheets into a single file I could then analyze (using Tableau.) If I did this by hand, I would have to open each file and copy/paste each worksheet. That's almost 100 copy/pastes, and it was very likely I would mess something up along the way.\n",
    "\n",
    "So I made a bash shell script that uses [csvkit](https://csvkit.readthedocs.org) to do the work for me. We'll replicate that here.\n",
    "\n",
    "We will:\n",
    "- download all the files using `curl` into our working directory\n",
    "- use csvkit commands to extract each sheet into a csv file\n",
    "- use csvkit to combine them into a single file\n",
    "\n",
    "(So you know, after I combined the file, I did some cleaning in Open Refine before visualizting in Tableau.)\n",
    "\n",
    "Of note: the speadsheet names that we need are:\n",
    "\n",
    "- AsstChief\n",
    "- Cmdr\n",
    "- Lt\n",
    "- Sgt\n",
    "- Det\n",
    "- Corp\n",
    "- PO\n",
    "- Cadets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directory to download data\n",
    "\n",
    "By this point, we should have already created our class directory inside of our home directory. Our next step is to create the folder where we will pull down our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/apd/data\r\n"
     ]
    }
   ],
   "source": [
    "# type these commands into your notebook\n",
    "# include this note with # at beginning:\n",
    "\n",
    "# set up folders if not there already\n",
    "# go to home folder, then Documents\n",
    "cd ~/Documents/rwd/\n",
    "\n",
    "# create apd inside class directory\n",
    "mkdir -p apd/\n",
    "\n",
    "# creeate data inside that directory\n",
    "mkdir -p apd/data/\n",
    "\n",
    "# create data-done directory\n",
    "mkdir -p apd/data-done/\n",
    "\n",
    "# go inside the data directory\n",
    "cd apd/data/\n",
    "\n",
    "# print working directory to make sure you are in it\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "We'll use a new command called `curl` to download our data. For more information on curl, you can read the [man page](https://curl.haxx.se/docs/manpage.html) or this [handy tip sheet](http://www.thegeekstuff.com/2012/04/curl-examples/), which is much more understandable.\n",
    "\n",
    "Since we are in a Bash notebook, we can use our command-line tools. We are going to pull down 12 files of a similar name. Before we do, let's break down the `curl` statement below.\n",
    "\n",
    "* `curl` is the command. I think of it as \"capture URL\". [man curl](http://man.cx/curl)\n",
    "* `-O` (that's capital O, not zero). This outputs result to a file to your computer instead of to your screen, using the same file name as it was originally.\n",
    "* `-L` stands for `--location`, and it will allow the request to follow a redirect link. It's good to use it.\n",
    "* And then we have the url of the file.\n",
    "  * We did something special in the URL to the file. There are 12 files, named 2005.xls, 2006.xls, etc., up to 2016.xls. We used brackets to give `curl` a series of filenames to process all at once. This works because the filenames are sequential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[1/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2005.xls --> 2005.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2005.xls\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  247k  100  247k    0     0   701k      0 --:--:-- --:--:-- --:--:--  788k\r\n",
      "\r\n",
      "[2/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2006.xls --> 2006.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2006.xls\r\n",
      "\r",
      "100  249k  100  249k    0     0  2039k      0 --:--:-- --:--:-- --:--:-- 2039k\r\n",
      "\r\n",
      "[3/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2007.xls --> 2007.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2007.xls\r\n",
      "\r",
      "100  254k  100  254k    0     0  2313k      0 --:--:-- --:--:-- --:--:-- 2313k\r\n",
      "\r\n",
      "[4/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2008.xls --> 2008.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2008.xls\r\n",
      "\r",
      "100  268k  100  268k    0     0  2442k      0 --:--:-- --:--:-- --:--:-- 2442k\r\n",
      "\r\n",
      "[5/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2009.xls --> 2009.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2009.xls\r\n",
      "\r",
      "100  271k  100  271k    0     0  2398k      0 --:--:-- --:--:-- --:--:-- 2398k\r\n",
      "\r\n",
      "[6/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2010.xls --> 2010.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2010.xls\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  294k  100  294k    0     0  1746k      0 --:--:-- --:--:-- --:--:-- 11.0M\r\n",
      "\r\n",
      "[7/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2011.xls --> 2011.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2011.xls\r\n",
      "\r",
      "100  283k  100  283k    0     0  2460k      0 --:--:-- --:--:-- --:--:-- 2460k\r\n",
      "\r\n",
      "[8/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2012.xls --> 2012.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2012.xls\r\n",
      "\r",
      "100  293k  100  293k    0     0  2379k      0 --:--:-- --:--:-- --:--:-- 2379k\r\n",
      "\r\n",
      "[9/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2013.xls --> 2013.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2013.xls\r\n",
      "\r",
      "100  297k  100  297k    0     0  2373k      0 --:--:-- --:--:-- --:--:-- 2373k\r\n",
      "\r\n",
      "[10/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2014.xls --> 2014.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2014.xls\r\n",
      "\r",
      "100  301k  100  301k    0     0  1989k      0 --:--:-- --:--:-- --:--:-- 1989k\r\n",
      "\r\n",
      "[11/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2015.xls --> 2015.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2015.xls\r\n",
      "\r",
      "100  311k  100  311k    0     0  2784k      0 --:--:-- --:--:-- --:--:-- 2784k\r\n",
      "\r\n",
      "[12/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2016.xls --> 2016.xls\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/2016.xls\r\n",
      "\r",
      "100  319k  100  319k    0     0  2670k      0 --:--:-- --:--:-- --:--:-- 2670k\r\n"
     ]
    }
   ],
   "source": [
    "# curl command to download files from my github repo\n",
    "curl -O -L https://raw.githubusercontent.com/utdata/cli-tools/master/data/apddemographics/[2005-2016].xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005.xls\t2008.xls\t2011.xls\t2014.xls\r\n",
      "2006.xls\t2009.xls\t2012.xls\t2015.xls\r\n",
      "2007.xls\t2010.xls\t2013.xls\t2016.xls\r\n"
     ]
    }
   ],
   "source": [
    "# Let's check that we got all the files. There should be 12 of them.\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect one of the files\n",
    "\n",
    "You should go ahead and open the 2005.xls file in Excel and take a look at it.\n",
    "\n",
    "- There are multiple worksheets in each file\n",
    "- Each file is set up exactly the same, with the same fields and the same worksheet names. This would fail if they were not that way. (I actually standardized all these files before this assignment. They were close, but not perfect.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/rwd/apd\r\n"
     ]
    }
   ],
   "source": [
    "# let's change our directory to come out of the data directory\n",
    "# so we can process all these files\n",
    "\n",
    "# cd up one directory\n",
    "cd ../\n",
    "\n",
    "# then check where we are. We should be in the apd directory\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert worksheets into csv files\n",
    "This command below is a bash loop that uses the csvkit command called [`in2csv`](https://csvkit.readthedocs.io/en/0.9.1/tutorial/1_getting_started.html#in2csv-the-excel-killer) to do a lot of processing of files all at once. There are 12 files, and they each have six worksheets that we want. This is like going into each file, then doing \"save as\" to make CSVs for each of the six worksheets. So 6 x 12 is 72 ... so 72 \"save as\" operations in one fell swoop.\n",
    "\n",
    "- `for` says we are starting loop, meaning we are going to repeat what is in `do` later.\n",
    "- `s` is a variable that is our marker for the worksheet names that follow.\n",
    "- `in` is setting up the array of worksheet names. We'll `do` everyhing for \"AsstChief\", then we'll come back to the top and `do` everything again, but for \"Cmdr\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Convert the worksheets of each file\n",
    "# It's probably best to copy and paste this into a new cell\n",
    "\n",
    "# set up loop with vars for each worksheet name in the files\n",
    "for s in AsstChief Cmdr Lt Sgt Det Corp PO Cadets\n",
    "\n",
    "# convert into csv for each sheet\n",
    "do\n",
    "    in2csv data/2005.xls --sheet $s > data-done/2005-$s.csv\n",
    "    in2csv data/2006.xls --sheet $s > data-done/2006-$s.csv\n",
    "    in2csv data/2007.xls --sheet $s > data-done/2007-$s.csv\n",
    "    in2csv data/2008.xls --sheet $s > data-done/2008-$s.csv\n",
    "    in2csv data/2009.xls --sheet $s > data-done/2009-$s.csv\n",
    "    in2csv data/2010.xls --sheet $s > data-done/2010-$s.csv\n",
    "    in2csv data/2011.xls --sheet $s > data-done/2011-$s.csv\n",
    "    in2csv data/2012.xls --sheet $s > data-done/2012-$s.csv\n",
    "    in2csv data/2013.xls --sheet $s > data-done/2013-$s.csv\n",
    "    in2csv data/2014.xls --sheet $s > data-done/2014-$s.csv\n",
    "    in2csv data/2015.xls --sheet $s > data-done/2015-$s.csv\n",
    "    in2csv data/2016.xls --sheet $s > data-done/2016-$s.csv\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking down the in2csv command\n",
    "\n",
    "- `in2csv` is the command we are using. It converts various tabular formats to a csv file.\n",
    "- data/20XX.xls is the file name we are working on.\n",
    "- --sheet is a parameter of `in2csv` that says process a specific worksheet in the file.\n",
    "- `$s` is the worksheet name we are working on in this pass. So the first pass would be \"AsstChief\", and the next pass would be \"Cmdr\".\n",
    "- `>` says take the result of the previous command and write it into a new file.\n",
    "- `data-done/20XX-$s.csv` is the new file name, but we are using the worksheet name as part of the file. So the first line of the first pass would be `2005-AsstChief.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the files you created\n",
    "\n",
    "If you opened up that folder on your computer while this was running, you could watch the 96 files being created. You could even open them in Atom or Sublime (or even Excel) to see what they look like. There is one file for every worksheet in every file.\n",
    "\n",
    "We'll just make sure they are there by listing the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-AsstChief.csv\t2009-AsstChief.csv\t2013-AsstChief.csv\r\n",
      "2005-Cadets.csv\t\t2009-Cadets.csv\t\t2013-Cadets.csv\r\n",
      "2005-Cmdr.csv\t\t2009-Cmdr.csv\t\t2013-Cmdr.csv\r\n",
      "2005-Corp.csv\t\t2009-Corp.csv\t\t2013-Corp.csv\r\n",
      "2005-Det.csv\t\t2009-Det.csv\t\t2013-Det.csv\r\n",
      "2005-Lt.csv\t\t2009-Lt.csv\t\t2013-Lt.csv\r\n",
      "2005-PO.csv\t\t2009-PO.csv\t\t2013-PO.csv\r\n",
      "2005-Sgt.csv\t\t2009-Sgt.csv\t\t2013-Sgt.csv\r\n",
      "2006-AsstChief.csv\t2010-AsstChief.csv\t2014-AsstChief.csv\r\n",
      "2006-Cadets.csv\t\t2010-Cadets.csv\t\t2014-Cadets.csv\r\n",
      "2006-Cmdr.csv\t\t2010-Cmdr.csv\t\t2014-Cmdr.csv\r\n",
      "2006-Corp.csv\t\t2010-Corp.csv\t\t2014-Corp.csv\r\n",
      "2006-Det.csv\t\t2010-Det.csv\t\t2014-Det.csv\r\n",
      "2006-Lt.csv\t\t2010-Lt.csv\t\t2014-Lt.csv\r\n",
      "2006-PO.csv\t\t2010-PO.csv\t\t2014-PO.csv\r\n",
      "2006-Sgt.csv\t\t2010-Sgt.csv\t\t2014-Sgt.csv\r\n",
      "2007-AsstChief.csv\t2011-AsstChief.csv\t2015-AsstChief.csv\r\n",
      "2007-Cadets.csv\t\t2011-Cadets.csv\t\t2015-Cadets.csv\r\n",
      "2007-Cmdr.csv\t\t2011-Cmdr.csv\t\t2015-Cmdr.csv\r\n",
      "2007-Corp.csv\t\t2011-Corp.csv\t\t2015-Corp.csv\r\n",
      "2007-Det.csv\t\t2011-Det.csv\t\t2015-Det.csv\r\n",
      "2007-Lt.csv\t\t2011-Lt.csv\t\t2015-Lt.csv\r\n",
      "2007-PO.csv\t\t2011-PO.csv\t\t2015-PO.csv\r\n",
      "2007-Sgt.csv\t\t2011-Sgt.csv\t\t2015-Sgt.csv\r\n",
      "2008-AsstChief.csv\t2012-AsstChief.csv\t2016-AsstChief.csv\r\n",
      "2008-Cadets.csv\t\t2012-Cadets.csv\t\t2016-Cadets.csv\r\n",
      "2008-Cmdr.csv\t\t2012-Cmdr.csv\t\t2016-Cmdr.csv\r\n",
      "2008-Corp.csv\t\t2012-Corp.csv\t\t2016-Corp.csv\r\n",
      "2008-Det.csv\t\t2012-Det.csv\t\t2016-Det.csv\r\n",
      "2008-Lt.csv\t\t2012-Lt.csv\t\t2016-Lt.csv\r\n",
      "2008-PO.csv\t\t2012-PO.csv\t\t2016-PO.csv\r\n",
      "2008-Sgt.csv\t\t2012-Sgt.csv\t\t2016-Sgt.csv\r\n"
     ]
    }
   ],
   "source": [
    "# list files in data-done\n",
    "ls data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the files into one\n",
    "\n",
    "Our next trick is to use the csvkit command called `csvstack` to combine all the small csv files into a single combined file. This works because they all have the same header row.\n",
    "\n",
    "Let's break it down before we run it:\n",
    "\n",
    "- `csvstack` is the command. [Read about it here](https://csvkit.readthedocs.io/en/0.9.1/tutorial/3_power_tools.html#csvstack-combining-subsets).\n",
    "- `--filenames` is a parameter that adds the filename as a column in each row. This way we know from where each row came. We need this so we know which year the data came from.\n",
    "- `data-done/20*.csv` is the files we want to combine. We could list them all, but I used a shortcut by using the wildcard * to grab all the files that start with \"20\" and end with \".csv\".\n",
    "- `> data-done/combined.csv` says to take the output of the csvstack command and put it into a new file by this name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Next is to CSVstack them using the filename as a grouping value\n",
    "# I can use the filename to pull ou the year later in OpenRefine.\n",
    "\n",
    "csvstack --filenames data-done/20*.csv > apd-demographics-2005-2016.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19352   39496 1553486 apd-demographics-2005-2016.csv\r\n"
     ]
    }
   ],
   "source": [
    "# We can get a line count on the finished file:\n",
    "wc apd-demographics-2005-2016.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group,Last Name,First Name,Middle Name,Gender,Ethnicity Code,Ethnicity Description,Job Title,Current Hire Date,Commission Date\r\n",
      "2005-AsstChief.csv,Ellison,Cathy,Joan,F,2,Black,Assistant Police Chief,1978-08-07,1979-02-23\r\n",
      "2005-AsstChief.csv,Coy,Ricky,L,M,1,White,Assistant Police Chief,1975-02-07,1976-11-21\r\n",
      "2005-AsstChief.csv,Dahlstrom,Robert,Eric,M,1,White,Assistant Police Chief,1977-07-18,1978-02-24\r\n",
      "2005-AsstChief.csv,McDonald,Michael,Charles,M,2,Black,Assistant Police Chief,1983-08-29,1984-08-17\r\n",
      "2005-AsstChief.csv,Landeros,Rudy,Garza,M,3,Hispanic,Assistant Police Chief,1981-10-05,1982-04-16\r\n",
      "2005-Cadets.csv,Egan,Rae,Ann,F,1,White,Police Cadet,2004-11-29,2004-11-29\r\n",
      "2005-Cadets.csv,Swarthout,Tracy,A,F,1,White,Police Cadet,2004-11-29,2004-11-29\r\n",
      "2005-Cadets.csv,Castillo,Trissey,Ann,F,3,Hispanic,Police Cadet,2004-11-29,2004-11-29\r\n",
      "2005-Cadets.csv,Medrano,Lori,J,F,3,Hispanic,Police Cadet,2004-11-29,2004-11-29\r\n"
     ]
    }
   ],
   "source": [
    "# Let's peek at the top of the file:\n",
    "head apd-demographics-2005-2016.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-Sgt.csv,Torres,Santiago,,M,3,Hispanic,Police Sergeant,2000-10-23,2001-05-25\r\n",
      "2016-Sgt.csv,Trejo,Alfred,Louis,M,3,Hispanic,Police Sergeant,1994-07-11,1995-01-06\r\n",
      "2016-Sgt.csv,Urias,Steve,,M,3,Hispanic,Police Sergeant,1989-06-05,1989-11-17\r\n",
      "2016-Sgt.csv,Vallejo,Carlos,J,M,3,Hispanic,Police Sergeant,2001-03-11,2001-10-19\r\n",
      "2016-Sgt.csv,Villanueva,Randy,W.,M,3,Hispanic,Police Sergeant,1998-04-13,1998-10-23\r\n",
      "2016-Sgt.csv,Wright,Matthew,,M,3,Hispanic,Police Sergeant,2000-10-23,2001-05-25\r\n",
      "2016-Sgt.csv,Yates,Carl,Kevin,M,4.0,American Indian/Aleutian,Police Sergeant,1990-08-06,1991-02-01\r\n",
      "2016-Sgt.csv,Bauzon,Jerome,Cortez,M,5,Asian/Pacific Islander,Police Sergeant,1993-07-12,1994-01-07\r\n",
      "2016-Sgt.csv,Lee,Shane,Ying,M,5,Asian/Pacific Islander,Police Sergeant,1992-03-23,1992-09-16\r\n",
      "2016-Sgt.csv,Rohre,Charles,A,M,5,Asian/Pacific Islander,Police Sergeant,1999-01-04,1999-07-09\r\n"
     ]
    }
   ],
   "source": [
    "# and the bottom of the file:\n",
    "tail apd-demographics-2005-2016.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Open the finished file\n",
    "\n",
    "Now if you go open the `apd-demographics-2005-2016.csv` file, you'll see 19,353 rows of data that all came from our 96 files, which were all extracted from our 12 Excel files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeling lucky?\n",
    "\n",
    "If everything went right, you can delete your `apd` folder, then go back to the top of the workbook, then go under to the Cell > Run All menu and it will do all your steps again, and you'll have your finished file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next with this analysis?\n",
    "\n",
    "When I worked on this file, I next pulled it into Open Refine and I used the filename column to create a \"Year\" column, along with some other little cleanup here and there.\n",
    "\n",
    "I then exported that and pulled it into Tableau so I could see how demographics changed in APD over the years.\n",
    "\n",
    "What questions would you ask this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn in your files\n",
    "\n",
    "- Save your jupyter notebook that you are working on\n",
    "- close the windows\n",
    "- Go to your terminal and do Control-c, then say 'yes' to shutting down the server\n",
    "- Go to your finder or file browser and find the `apd` folder inside your `Documents/rwd/` folder. Compress that folder into a .zip file (how to [Mac](http://osxdaily.com/2012/01/10/how-to-zip-files-in-mac-os-x/) or [PC](https://support.microsoft.com/en-us/help/14200/windows-compress-uncompress-zip-files)) and upload to the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
